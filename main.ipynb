{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57dea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force IPython to auto-flush outputs\n",
    "%config Application.log_level = 'INFO' \n",
    "%config InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20df530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import sys\n",
    "import os\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea354f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53088d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crimson leaves descend,  \n",
      "Whispers of the cooling breeze,  \n",
      "Autumn’s soft farewell.\n",
      "content='Crimson leaves descend,  \\nWhispers of the cooling breeze,  \\nAutumn’s soft farewell.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 26, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CIdVoFw1dUCaHtVymQCTKd1fMKZsD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--e5f80354-8fbf-4a37-be43-1a2b04972a96-0' usage_metadata={'input_tokens': 26, 'output_tokens': 20, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Single LLM Call\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # best practice\n",
    "    request_timeout=120,\n",
    "    max_retries=5,\n",
    "    verbose=False,\n",
    "   \n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"assistant\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Write me a haiku about autumn leaves.\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "res = llm.invoke(messages)   # list-of-conversations -> ChatResult\n",
    "\n",
    "print(res.content) \n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfadaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime la programmation.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b5ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 18, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CIdVqEXt3LfwKUvDbF8727DFSb60W', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e1d461b6-56f7-4f6c-b7b0-bfcc1a75a4e4-0', usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Crimson leaves descend,  \\nWhispering tales to the breeze,  \\nAutumn’s soft farewell.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 16, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CIdVqv7ippl1riWj2rrKd3LPAJMlo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--16ea0614-abe7-4e7d-95b4-1075b79e7fad-0', usage_metadata={'input_tokens': 16, 'output_tokens': 21, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 18, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CIdVrQNRNR6zuWECNcVyRTzRm5RNY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--2ffa08d9-c245-4a81-9277-b9dcde236feb-0', usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Crimson leaves descend,  \\nWhispers of the cooling breeze,  \\nAutumn’s soft farewell.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 16, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CIdVqiM5ag9gog7SL6r2ZMGNdT27c', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--953ae632-aa50-4ca0-8577-6a65500abb93-0', usage_metadata={'input_tokens': 16, 'output_tokens': 20, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 18, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CIdVq4gqj2i3N82DCuFkBDPs1bWzr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--aa23af66-0e5a-40be-b3a7-a5063cd49a76-0', usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Crimson leaves descend,  \\nWhispers of the cooling breeze,  \\nAutumn’s soft farewell.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 16, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CIdVrsVUzn1czuQHrPI5BTDIi4B5M', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--920eacaf-8c60-4582-a96b-c5d916702d90-0', usage_metadata={'input_tokens': 16, 'output_tokens': 20, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 18, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CIdVrqhWFhvPhhFXb4HyzgHYruwEb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b03f7ed5-1638-4242-9c38-97de6a160c64-0', usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Crimson leaves descend,  \\nWhispers of the cooling breeze,  \\nAutumn’s soft farewell.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 16, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CIdVqIq61yxbNDRis1Y0oPPNjJhvY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9709daf7-5772-4bba-a483-12bbf91d822c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 20, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 18, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CIdVrKDSMcdPx3lfk3cCZOPbCJdxa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0743a661-e204-489a-a6c2-64fe0af6ffdd-0', usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Crimson leaves descend,  \\nWhispers of the cooling breeze,  \\nAutumn’s soft farewell.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 16, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CIdVqTRAjBOefSkR7mYp3bWLKY3tn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--cc88b51f-45a0-4fd7-8328-cb2fb2a7da28-0', usage_metadata={'input_tokens': 16, 'output_tokens': 20, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "\n",
      "CHOICE 1\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "CHOICE 2\n",
      "\n",
      "Crimson leaves descend,  \n",
      "Whispering tales to the breeze,  \n",
      "Autumn’s soft farewell.\n",
      "\n",
      "\n",
      "CHOICE 3\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "CHOICE 4\n",
      "\n",
      "Crimson leaves descend,  \n",
      "Whispers of the cooling breeze,  \n",
      "Autumn’s soft farewell.\n",
      "\n",
      "\n",
      "CHOICE 5\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "CHOICE 6\n",
      "\n",
      "Crimson leaves descend,  \n",
      "Whispers of the cooling breeze,  \n",
      "Autumn’s soft farewell.\n",
      "\n",
      "\n",
      "CHOICE 7\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "CHOICE 8\n",
      "\n",
      "Crimson leaves descend,  \n",
      "Whispers of the cooling breeze,  \n",
      "Autumn’s soft farewell.\n",
      "\n",
      "\n",
      "CHOICE 9\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "CHOICE 10\n",
      "\n",
      "Crimson leaves descend,  \n",
      "Whispers of the cooling breeze,  \n",
      "Autumn’s soft farewell.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    # Batched LLM Calls\n",
    "    from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "    messages = [\n",
    "        (\"assistant\", \"You are a helpful assistant.\"),\n",
    "        ([HumanMessage(\"Write me a haiku about autumn leaves.\")])\n",
    "    ] * 5\n",
    "\n",
    "    completion = llm.batch(messages)  # list-of-list-of-conversations -> ChatResult\n",
    "\n",
    "    print(completion)\n",
    "\n",
    "    for i, choice in enumerate(completion):\n",
    "        print(f\"\\n\\nCHOICE {i+1}\\n\")\n",
    "        print(choice.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cbf2e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 26, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_3502f4eb73', 'id': 'chatcmpl-CIdxhK63PXDJwRxcPYrbUc32331Gc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--782bb7b5-a841-4908-a517-547c7a75f9eb-0', usage_metadata={'input_tokens': 26, 'output_tokens': 4, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"French\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e572ccc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001B653BD24E0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B653BD0B60>, root_client=<openai.OpenAI object at 0x000001B653B42D50>, root_async_client=<openai.AsyncOpenAI object at 0x000001B653BD2360>, model_name='gpt-4.1', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51169d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # how to have an interactive real time conversation with the assistant?\n",
    "\n",
    "    # Initialise model\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "    def ask_once(user_input: str):\n",
    "        # Only system + user, no history\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "            HumanMessage(content=user_input)\n",
    "        ]\n",
    "        response = llm.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "    # Run a simple q&a session\n",
    "    i=0\n",
    "    while True:\n",
    "        user_input = input(f\"Q{i+1}: \")   # prompt user in Jupyter cell\n",
    "        if user_input == \"quit\" or user_input == \"exit\" or user_input == \"break\" or not user_input.strip():        # allow empty string or quit or exit or break to break early\n",
    "            break\n",
    "        answer = ask_once(user_input)\n",
    "        i += 1\n",
    "        print(f\"Assistant: {answer}\\n\")\n",
    "\n",
    "        # Example questions are: where were the last olympics held?  who won the world cup in 2022?  Who wa the team captain? what is the capital of france? who is the president of the united states? what is the tallest mountain in the world?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ecfb1",
   "metadata": {},
   "source": [
    "What did you notice about this Assistant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ae6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # What is diffeernt about this version?\n",
    "\n",
    "    # initialise model\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "    # start with a system prompt\n",
    "    history = [SystemMessage(content=\"You are a helpful assistant.\")]\n",
    "\n",
    "    # function to ask user input and continue the conversation\n",
    "    def chat_turn(user_input: str):\n",
    "        # append user message\n",
    "        history.append(HumanMessage(content=user_input))\n",
    "\n",
    "        # call model with full history\n",
    "        ai_msg = llm.invoke(history)  # returns an AIMessage\n",
    "        #print(f\"Assistant: {ai_msg.content}\")\n",
    "\n",
    "        # append assistant reply manually (so it's fed into the next turn)\n",
    "        history.append(ai_msg)\n",
    "        return ai_msg.content\n",
    "\n",
    "    # Run a simple q&a session\n",
    "    i=0\n",
    "    while True:\n",
    "        user_input = input(f\"Q{i+1}: \")   # prompt user in Jupyter cell\n",
    "        if user_input == \"quit\" or user_input == \"exit\" or user_input == \"break\" or not user_input.strip():        # allow empty string or quit or exit or break to break early\n",
    "            break\n",
    "        answer = chat_turn(user_input)\n",
    "        i += 1\n",
    "        print(f\"Assistant: {answer}\\n\")\n",
    "\n",
    "        # Example questions are: where were the last olympics held?  who won the world cup in 2022?  Who wa the team captain? what is the capital of france? who is the president of the united states? what is the tallest mountain in the world?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # And about this version?\n",
    "\n",
    "    # initialise model\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0, output_version=\"responses/v1\")\n",
    "\n",
    "    tool = {\"type\": \"web_search_preview\"}\n",
    "    llm_with_tools = llm.bind_tools([tool])\n",
    "\n",
    "    # start with a system prompt\n",
    "    history = [SystemMessage(content=\"You are a helpful assistant.\")]\n",
    "\n",
    "    # function to ask user input and continue the conversation\n",
    "    def chat_turn(user_input: str):\n",
    "        # append user message\n",
    "        history.append(HumanMessage(content=user_input))\n",
    "\n",
    "        # call model with full history\n",
    "        ai_msg = llm_with_tools.invoke(history)  # returns an AIMessage\n",
    "        #print(f\"Assistant: {ai_msg.content}\")\n",
    "\n",
    "        # append assistant reply manually (so it's fed into the next turn)\n",
    "        history.append(ai_msg)\n",
    "        return ai_msg.text()\n",
    "\n",
    "    # Run a simple q&a session\n",
    "    i=0\n",
    "    while True:\n",
    "        user_input = input(f\"Q{i+1}: \")   # prompt user in Jupyter cell\n",
    "        if user_input == \"quit\" or user_input == \"exit\" or user_input == \"break\" or not user_input.strip():        # allow empty string or quit or exit or break to break early\n",
    "            break\n",
    "        answer = chat_turn(user_input)\n",
    "        i += 1\n",
    "        print(f\"Assistant: {answer}\\n\")\n",
    "        print({answer})\n",
    "\n",
    "        # Example questions are: where were the last olympics held?  who won the world cup in 2022?  Who wa the team captain? what is the capital of france? who is the president of the united states? what is the tallest mountain in the world?\n",
    "        # who won the women's 100m  hurldes at the 2025 tokyo world athletics championship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbb4f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae42a4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"answer\":\"A pound of feathers and a pound of gold both weigh the same: one pound.\",\"justification\":\"The weight measurement 'pound' is the same unit for both, so a pound of any substance, including feathers and gold, is equal in weight. However, in commercial and scientific settings, gold is often measured using 'troy pounds' (which is about 373 grams) while feathers use 'avoirdupois pounds' (about 454 grams). If using these different systems, the avoirdupois pound (used for feathers) is heavier than the troy pound (used for gold). But when referring simply to 'a pound' as a common unit, they weigh the same.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "def get_weather(location: str) -> None:\n",
    "    \"\"\"Get weather at a location.\"\"\"\n",
    "    return \"It's sunny.\"\n",
    "\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    \"\"\"Schema for response.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    justification: str\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "\n",
    "structured_llm = llm.bind_tools(\n",
    "    [get_weather],\n",
    "    response_format=OutputSchema,\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "# Response contains tool calls:\n",
    "tool_call_response = structured_llm.invoke(\"What is the weather in SF?\")\n",
    "\n",
    "# structured_response.additional_kwargs[\"parsed\"] contains parsed output\n",
    "structured_response = structured_llm.invoke(\n",
    "    \"What weighs more, a pound of feathers or a pound of gold?\"\n",
    ")\n",
    "print(structured_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a tool call\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"city\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in London?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888010fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intern_GenAI_Examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
